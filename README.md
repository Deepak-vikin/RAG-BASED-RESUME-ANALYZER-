## ⚠️ Ollama Setup (Required)

This project uses a **local LLM via Ollama**.

### Install Ollama
https://ollama.com

### Pull the model
```In bash
ollama pull llama3
